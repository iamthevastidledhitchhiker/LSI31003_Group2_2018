{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import keras.optimizers\n",
    "from Calibration_Util import DataHandler as dh\n",
    "from Calibration_Util import FileIO as io\n",
    "from keras.layers import Input, Dense, merge, Activation, add\n",
    "from keras.models import Model\n",
    "from keras import callbacks as cb\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "#detect display\n",
    "import os\n",
    "havedisplay = \"DISPLAY\" in os.environ\n",
    "#if we have a display use a plotting backend\n",
    "if havedisplay:\n",
    "    matplotlib.use('TkAgg')\n",
    "else:\n",
    "    matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CostFunctions as cf\n",
    "import Monitoring as mn\n",
    "from keras.regularizers import l2\n",
    "from sklearn import decomposition\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "import ScatterHist as sh\n",
    "from keras import initializers\n",
    "from numpy import genfromtxt\n",
    "import sklearn.preprocessing as prep\n",
    "import tensorflow as tf\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration hyper parameters\n",
    "denoise = False # whether or not to train a denoising autoencoder to remove the zeros\n",
    "keepProb=.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AE confiduration\n",
    "ae_encodingDim = 25\n",
    "l2_penalty_ae = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MMD net configuration\n",
    "mmdNetLayerSizes = [25, 25]\n",
    "l2_penalty = 1e-2\n",
    "#init = lambda shape, name:initializations.normal(shape, scale=.1e-4, name=name)\n",
    "#def my_init (shape):\n",
    "#    return initializers.normal(stddev=.1e-4)\n",
    "#my_init = 'glorot_normal'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "###### read data ######\n",
    "#######################\n",
    "# we load two CyTOF samples\n",
    "\n",
    "data = 'person1_3month'\n",
    "\n",
    "if data =='person1_baseline':\n",
    "    sourcePath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day1_baseline.csv')\n",
    "    targetPath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day2_baseline.csv')\n",
    "if data =='person2_baseline':\n",
    "    sourcePath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day1_baseline.csv')\n",
    "    targetPath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day2_baseline.csv')\n",
    "if data =='person1_3month':\n",
    "    sourcePath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day1_3month.csv')\n",
    "    targetPath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day2_3month.csv')\n",
    "if data =='person2_3month':\n",
    "    sourcePath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day1_3month.csv')\n",
    "    targetPath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day2_3month.csv')\n",
    "\n",
    "source = genfromtxt(sourcePath, delimiter=',', skip_header=0)\n",
    "target = genfromtxt(targetPath, delimiter=',', skip_header=0)\n",
    "\n",
    "# pre-process data: log transformation, a standard practice with CyTOF data\n",
    "target = dh.preProcessCytofData(target)\n",
    "source = dh.preProcessCytofData(source)\n",
    "\n",
    "numZerosOK=1\n",
    "toKeepS = np.sum((source==0), axis = 1) <=numZerosOK\n",
    "print(np.sum(toKeepS))\n",
    "toKeepT = np.sum((target==0), axis = 1) <=numZerosOK\n",
    "print(np.sum(toKeepT))\n",
    "\n",
    "inputDim = target.shape[1]\n",
    "\n",
    "if denoise:\n",
    "    trainTarget_ae = np.concatenate([source[toKeepS], target[toKeepT]], axis=0)\n",
    "    np.random.shuffle(trainTarget_ae)\n",
    "    trainData_ae = trainTarget_ae * np.random.binomial(n=1, p=keepProb, size = trainTarget_ae.shape)\n",
    "    input_cell = Input(shape=(inputDim,))\n",
    "    encoded = Dense(ae_encodingDim, activation='relu',W_regularizer=l2(l2_penalty_ae))(input_cell)\n",
    "    encoded1 = Dense(ae_encodingDim, activation='relu',W_regularizer=l2(l2_penalty_ae))(encoded)\n",
    "    decoded = Dense(inputDim, activation='linear',W_regularizer=l2(l2_penalty_ae))(encoded1)\n",
    "    autoencoder = Model(input=input_cell, output=decoded)\n",
    "    autoencoder.compile(optimizer='rmsprop', loss='mse')\n",
    "    autoencoder.fit(trainData_ae, trainTarget_ae, epochs=500, batch_size=128, shuffle=True,  validation_split=0.1,\n",
    "                    callbacks=[mn.monitor(), cb.EarlyStopping(monitor='val_loss', patience=25,  mode='auto')])\n",
    "    source = autoencoder.predict(source)\n",
    "    target = autoencoder.predict(target)\n",
    "\n",
    "# rescale source to have zero mean and unit variance\n",
    "# apply same transformation to the target\n",
    "preprocessor = prep.StandardScaler().fit(source)\n",
    "source = preprocessor.transform(source)\n",
    "target = preprocessor.transform(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "######## Build MMD net ######\n",
    "#############################\n",
    "calibInput = Input(shape=(inputDim,))\n",
    "block1_bn1 = BatchNormalization()(calibInput)\n",
    "block1_a1 = Activation('relu')(block1_bn1)\n",
    "block1_w1 = Dense(mmdNetLayerSizes[0], activation='linear',kernel_regularizer=l2(l2_penalty),\n",
    "                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block1_a1)\n",
    "block1_bn2 = BatchNormalization()(block1_w1)\n",
    "block1_a2 = Activation('relu')(block1_bn2)\n",
    "block1_w2 = Dense(inputDim, activation='linear',kernel_regularizer=l2(l2_penalty),\n",
    "                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block1_a2)\n",
    "block1_output = add([block1_w2, calibInput])\n",
    "block2_bn1 = BatchNormalization()(block1_output)\n",
    "block2_a1 = Activation('relu')(block2_bn1)\n",
    "block2_w1 = Dense(mmdNetLayerSizes[1], activation='linear',kernel_regularizer=l2(l2_penalty),\n",
    "                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block2_a1)\n",
    "block2_bn2 = BatchNormalization()(block2_w1)\n",
    "block2_a2 = Activation('relu')(block2_bn2)\n",
    "block2_w2 = Dense(inputDim, activation='linear',kernel_regularizer=l2(l2_penalty),\n",
    "                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block2_a2)\n",
    "block2_output = add([block2_w2, block1_output])\n",
    "block3_bn1 = BatchNormalization()(block2_output)\n",
    "block3_a1 = Activation('relu')(block3_bn1)\n",
    "block3_w1 = Dense(mmdNetLayerSizes[1], activation='linear',kernel_regularizer=l2(l2_penalty),\n",
    "                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block3_a1)\n",
    "block3_bn2 = BatchNormalization()(block3_w1)\n",
    "block3_a2 = Activation('relu')(block3_bn2)\n",
    "block3_w2 = Dense(inputDim, activation='linear',kernel_regularizer=l2(l2_penalty),\n",
    "                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block3_a2)\n",
    "block3_output = add([block3_w2, block2_output])\n",
    "\n",
    "calibMMDNet = Model(inputs=calibInput, outputs=block3_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.1\n",
    "    epochs_drop = 150.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "lrate = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "######## train MMD net ######\n",
    "#############################\n",
    "\n",
    "#train MMD net\n",
    "optimizer = keras.optimizers.rmsprop(lr=0.0)\n",
    "\n",
    "calibMMDNet.compile(optimizer=optimizer, loss=lambda y_true,y_pred:\n",
    "               cf.MMD(block3_output,target,MMDTargetValidation_split=0.1).KerasCost(y_true,y_pred))\n",
    "K.get_session().run(tf.global_variables_initializer())\n",
    "\n",
    "sourceLabels = np.zeros(source.shape[0])\n",
    "calibMMDNet.fit(source,sourceLabels,epochs=5000,batch_size=1000,validation_split=0.1,verbose=1,\n",
    "           callbacks=[lrate, mn.monitorMMD(source, target, calibMMDNet.predict),\n",
    "                      cb.EarlyStopping(monitor='val_loss',patience=50,mode='auto')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################\n",
    "###### evaluate results ######\n",
    "##############################\n",
    "\n",
    "calibratedSource = calibMMDNet.predict(source)\n",
    "\n",
    "##################################### qualitative evaluation: PCA #####################################\n",
    "pca = decomposition.PCA()\n",
    "pca.fit(target)\n",
    "\n",
    "# project data onto PCs\n",
    "target_sample_pca = pca.transform(target)\n",
    "projection_before = pca.transform(source)\n",
    "projection_after = pca.transform(calibratedSource)\n",
    "\n",
    "# choose PCs to plot\n",
    "pc1 = 0\n",
    "pc2 = 1\n",
    "axis1 = 'PC'+str(pc1)\n",
    "axis2 = 'PC'+str(pc2)\n",
    "sh.scatterHist(target_sample_pca[:,pc1], target_sample_pca[:,pc2], projection_before[:,pc1], projection_before[:,pc2], axis1, axis2)\n",
    "sh.scatterHist(target_sample_pca[:,pc1], target_sample_pca[:,pc2], projection_after[:,pc1], projection_after[:,pc2], axis1, axis2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save models\n",
    "autoencoder.save(os.path.join(io.DeepLearningRoot(),'savedModels/person1_baseline_DAE.h5'))\n",
    "calibMMDNet.save_weights(os.path.join(io.DeepLearningRoot(),'savedModels/person1_baseline_ResNet_weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
